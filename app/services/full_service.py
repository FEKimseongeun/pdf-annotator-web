# app/services/full_service.py
import os
import logging
from typing import Dict
import pandas as pd
import fitz  # PyMuPDF
from flashtext import KeywordProcessor

logger = logging.getLogger(__name__)

COLOR_PALETTE = [
    (1, 1, 0),
    (0, 1, 0),
    (0, 1, 1),
    (1, 0, 1),
    (1, 0.5, 0),
    (0.5, 0.5, 1),
    (0.8, 0.8, 0.8)
]


def annotate_pdf_with_excel(
        excel_path: str,
        pdf_input_path: str,
        pdf_output_path: str,
        not_found_xlsx_path: str,
        opacity: float = 0.35,
        **kwargs
) -> Dict:
    logger.info("=" * 60)
    logger.info("Full tag ì²˜ë¦¬ ì‹œì‘")
    logger.info(f"ì—‘ì…€: {os.path.basename(excel_path)}")
    logger.info(f"PDF: {os.path.basename(pdf_input_path)}")
    logger.info("=" * 60)

    if not os.path.exists(excel_path):
        raise FileNotFoundError(f"ì—‘ì…€ íŒŒì¼ ì—†ìŒ: {excel_path}")
    if not os.path.exists(pdf_input_path):
        raise FileNotFoundError(f"PDF íŒŒì¼ ì—†ìŒ: {pdf_input_path}")

    logger.info("ğŸ“Š ì—‘ì…€ íŒŒì¼ ë¡œë”© ì¤‘...")
    df = pd.read_excel(excel_path)
    logger.info(f"   - ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
    logger.info(f"   - ì»¬ëŸ¼ ëª©ë¡: {list(df.columns)}")

    keyword_processor = KeywordProcessor(case_sensitive=False)
    keyword_metadata = {}
    all_keywords_map = {}
    total_keywords = 0

    logger.info("ğŸ” ê²€ìƒ‰ ì—”ì§„ êµ¬ì¶• ì¤‘...")
    for idx, col_header in enumerate(df.columns):
        color = COLOR_PALETTE[idx % len(COLOR_PALETTE)]
        col_keyword_count = 0

        for keyword in df[col_header].dropna():
            word_str = str(keyword).strip()
            if not word_str:
                continue

            keyword_processor.add_keyword(word_str)
            word_lower = word_str.lower()

            keyword_metadata[word_lower] = {
                "header": str(col_header),
                "color": color,
                "original_word": word_str
            }

            all_keywords_map[word_lower] = {
                'word': word_str,
                'header': str(col_header)
            }

            total_keywords += 1
            col_keyword_count += 1

        logger.info(f"   - {col_header}: {col_keyword_count}ê°œ í‚¤ì›Œë“œ")

    if not all_keywords_map:
        raise ValueError("ì—‘ì…€ì—ì„œ ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    logger.info(f"âœ… ì´ {total_keywords}ê°œ í‚¤ì›Œë“œ ë“±ë¡ ì™„ë£Œ")

    logger.info("ğŸ“„ PDF íŒŒì¼ ì—´ê¸° ì¤‘...")
    found_keywords = set()
    total_hits = 0
    failed_pages = []

    try:
        doc = fitz.open(pdf_input_path)

        if doc.is_repaired:
            logger.warning("âš ï¸  PDFê°€ ì†ìƒë˜ì–´ ìë™ ë³µêµ¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

        num_pages = len(doc)
        logger.info(f"   - ì´ í˜ì´ì§€ ìˆ˜: {num_pages}")
        logger.info("=" * 60)

        for page_num in range(num_pages):
            logger.info(f"ğŸ“– í˜ì´ì§€ {page_num + 1}/{num_pages} ì²˜ë¦¬ ì¤‘...")

            try:
                page = doc.load_page(page_num)

                try:
                    text_on_page = page.get_text("text")
                    text_length = len(text_on_page)
                    logger.info(f"   - í…ìŠ¤íŠ¸ ì¶”ì¶œ: {text_length}ì")
                except Exception as e:
                    logger.error(f"âŒ í˜ì´ì§€ {page_num + 1} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    failed_pages.append(page_num + 1)
                    continue

                keywords_on_page = keyword_processor.extract_keywords(text_on_page)
                unique_keywords_on_page = set(keywords_on_page)

                if not unique_keywords_on_page:
                    logger.info(f"   - ë°œê²¬ëœ í‚¤ì›Œë“œ: 0ê°œ")
                    continue

                logger.info(f"   - ë°œê²¬ëœ í‚¤ì›Œë“œ: {len(unique_keywords_on_page)}ê°œ")
                found_keywords.update(k.lower() for k in unique_keywords_on_page)
                page_hits = 0

                for keyword in unique_keywords_on_page:
                    keyword_lower = keyword.lower()

                    try:
                        quads = page.search_for(keyword)
                        quad_count = len(quads)

                        if quad_count > 0:
                            logger.debug(f"      Â· '{keyword}': {quad_count}ê°œ ìœ„ì¹˜ ë°œê²¬")
                    except Exception as e:
                        logger.error(f"âŒ í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                        continue

                    meta = keyword_metadata.get(keyword_lower)
                    if not meta:
                        continue

                    annot_title = meta['header']
                    annot_color = meta['color']

                    for quad in quads:
                        try:
                            annot = page.add_highlight_annot(quad)
                            annot.set_colors(stroke=annot_color)
                            annot.set_opacity(opacity)
                            annot.set_info(content=keyword, title=annot_title)
                            annot.update()
                            total_hits += 1
                            page_hits += 1
                        except Exception as e:
                            logger.error(f"âŒ í•˜ì´ë¼ì´íŠ¸ ì¶”ê°€ ì‹¤íŒ¨: {e}")
                            continue

                logger.info(f"   âœ… í˜ì´ì§€ {page_num + 1} ì™„ë£Œ: {page_hits}ê°œ í•˜ì´ë¼ì´íŠ¸ ì¶”ê°€")

            except Exception as e:
                logger.error(f"âŒ í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                failed_pages.append(page_num + 1)
                continue

        logger.info("=" * 60)
        logger.info("ğŸ’¾ PDF ì €ì¥ ì¤‘...")

        try:
            doc.save(pdf_output_path)
            logger.info(f"âœ… PDF ì €ì¥ ì™„ë£Œ: {os.path.basename(pdf_output_path)}")
        except Exception as e:
            logger.warning(f"âš ï¸  ì••ì¶• ì €ì¥ ì‹¤íŒ¨, ì¼ë°˜ ì €ì¥ ì‹œë„: {e}")
            doc.save(pdf_output_path)
            logger.info(f"âœ… PDF ì €ì¥ ì™„ë£Œ (ì¼ë°˜ ëª¨ë“œ)")

        doc.close()

    except Exception as e:
        logger.error(f"âŒ PDF ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise RuntimeError(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    logger.info("=" * 60)
    logger.info("ğŸ“Š ê²°ê³¼ ì§‘ê³„ ì¤‘...")

    all_keys = set(all_keywords_map.keys())
    missing_keys = all_keys - found_keywords
    not_found_count = len(missing_keys)

    logger.info(f"   - ì „ì²´ í‚¤ì›Œë“œ: {total_keywords}ê°œ")
    logger.info(f"   - ë°œê²¬ëœ í‚¤ì›Œë“œ: {len(found_keywords)}ê°œ")
    logger.info(f"   - ë¯¸ë°œê²¬ í‚¤ì›Œë“œ: {not_found_count}ê°œ")
    logger.info(f"   - ì´ í•˜ì´ë¼ì´íŠ¸: {total_hits}ê°œ")

    if failed_pages:
        logger.warning(f"âš ï¸  ì²˜ë¦¬ ì‹¤íŒ¨ í˜ì´ì§€: {failed_pages}")

    if missing_keys:
        logger.info("ğŸ“ ë¯¸ë°œê²¬ í‚¤ì›Œë“œ ì—‘ì…€ ìƒì„± ì¤‘...")
        missing_data_list = []
        for key in missing_keys:
            info = all_keywords_map[key]
            missing_data_list.append({
                'Header': info['header'],
                'Keyword': info['word'],
                'Status': 'Not Found'
            })

        missing_df = pd.DataFrame(missing_data_list).sort_values(by=['Header', 'Keyword'])
        missing_df.to_excel(not_found_xlsx_path, index=False)
        logger.info(f"âœ… ë¯¸ë°œê²¬ ëª©ë¡ ì €ì¥: {os.path.basename(not_found_xlsx_path)}")
    else:
        logger.info("ğŸ‰ ëª¨ë“  í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤!")

    logger.info("=" * 60)
    logger.info("âœ… Full tag ì²˜ë¦¬ ì™„ë£Œ")
    logger.info("=" * 60)

    return {
        "pages": num_pages,
        "terms": total_keywords,
        "hits": total_hits,
        "not_found_count": not_found_count,
        "failed_count": len(failed_pages),
    }